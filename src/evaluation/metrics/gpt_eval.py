
import json

from utils import extract_json



GPT_CONTENT_SCORE_PROMPT = """
    You are an expert evaluator for large language models.
    You will be given:
        - a prompt (describing the task the system should perform)
        - an utterance (the user's input question)
        - a response generated by the large language models
    
    Your task is to evaluate the quality of the response based on the following criteria:
    
    Instruction: [PROMPT]
    
    Input text: [QUESTION]
    
    Response: [PRED]
    
    Evaluation from following ascpects:
        - Fluency: Is the response grammatically correct and natural-sounding? (1-5, 5 being best)
        - Relevance: Does the response directly and appropriately address the prompt and the utterance? (1-5, 5 being best)
        - Overall Score: Taking all factors into account, what is the overall quality of the response? (1-5, 5 being best)
        
    MUST provide your evaluation ONLY in ***JSON FORMAT***:
    {
        "fluency": <score>,
        "relevance": <score>,
        "overall_score": <score>
        "details": <reasons>
    }
"""

GPT_EMPATHY_SCORE_PROMPT = """
    You will be provided with a response generated based on the following input text and emotional information:
    Input Text: [QUESTION]
    Emotional Information: [EMOTION]

    Your task is to assess the quality of the response in relation to the emotional context and intent of the original question. Please evaluate the response based on the following criteria and provide a score from 1 (poor) to 5 (excellent) for each:
    1. Empathy: How effectively does the response acknowledge and respond to the emotional state of the questioner?
    2. Content: How well does the response stay on-topic and provide an appropriate reply to the question?
    3. Clarity: How clear and easy to understand is the response?


    Generated Response: [PRED]
    Your *entire response* MUST be a single, valid JSON string. NOT A MARKDOWN FORMAT!!!

    Use the following JSON string precisely:
    {
        "score": {
            "empathy": <score>,
            "content": <score>,
            "clarity": <score>
        },
        "details": {
            "empathy": <reason>,
            "content": <reason>,
            "clarity": <reason>
        }
    }
"""


def gpt_content_score(client, data):
    """
    使用 GPT 计算分数
    Args:
        client: GPT 客户端实例
        prompt: 提示词
    Returns:
        float: GPT 计算的分数
    """
    prompt = GPT_CONTENT_SCORE_PROMPT

    fluency_score = 0
    relevance_score = 0
    overall_score = 0

    for item in data:
        prompt = build_content_score_prompt(item)
        response = client.generate_response(prompt)
        json_str = extract_json(response)
        try:
            json_response = json.loads(json_str)
            fluency = json_response['fluency']
            relevance = json_response['relevance']
            overall = json_response['overall_score']
        except BaseException as e:
            print("Response formant error")
            print(e)
            print(response)
            print('#' * 20)
            print(json_str)
            continue
        fluency_score += fluency
        relevance_score += relevance

        overall_score += overall
    fluency_score = fluency_score / len(data)
    relevance_score = relevance_score / len(data)
    overall_score = overall_score / len(data)
    return {
        'scores': {
            'fluency': fluency_score,
            'relevance': relevance_score,
            'overall': overall_score
        },
    }

def gpt_empathy_score(client, data):
    """
    使用 GPT 计算分数
    Args:
        client: GPT 客户端实例
        prompt: 提示词
    Returns:
        float: GPT 计算的分数
    """
    empathy_score = 0
    content_score = 0
    clarity_score = 0
    for item in data:
        prompt = build_empathy_prompt(item)
        response = client.generate_response(prompt)
        try:
            json_response = json.loads(response)
            empathy = json_response['score']['empathy']
            content = json_response['score']['content']
            clarity = json_response['score']['clarity']
        except json.JSONDecodeError as e:
            print("Response formant error")
            print(e)
            print(response)
            continue
        empathy_score += empathy
        content_score += content
        clarity_score += clarity

    empathy_score = empathy_score / len(data)
    content_score = content_score / len(data)
    clarity_score = clarity_score / len(data)
    scores = {
        'empathy': empathy_score,
        'content': content_score,
        'clarity': clarity_score,
        'overall': (empathy_score + content_score + clarity_score) / 3
    }
    return {
        'scores': scores,
    }

def build_empathy_prompt(item):
    prompt = GPT_EMPATHY_SCORE_PROMPT
    prompt = prompt.replace("[QUESTION]", item['question'])
    prompt = prompt.replace("[Emotion]", 'happy')
    prompt = prompt.replace("[PRED]", item['pred'])
    return prompt

def build_content_score_prompt(item):
    prompt = GPT_CONTENT_SCORE_PROMPT
    prompt = prompt.replace("[PROMPT]", item['prompt'])
    prompt = prompt.replace("[QUESTION]", item['question'])
    prompt = prompt.replace("[PRED]", item['pred'])
    return prompt